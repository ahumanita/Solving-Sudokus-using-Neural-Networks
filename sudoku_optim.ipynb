{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sudoku_optim.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TKeKJZCeYQ7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "zbSIZDbVYO2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CONV_LAYERS = 5\n",
        "FILTERS = 256\n",
        "FC_LAYERS = 3\n",
        "NEURONS = 1500\n",
        "KERNEL = 3\n",
        "PADDING = 1\n",
        "learning_rate = .00001\n",
        "\n",
        "num_epochs = 20\n",
        "num_classes = 9\n",
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v51onS_yZQzV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "hKCDXqslZ2cd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ]
    },
    {
      "metadata": {
        "id": "s161d-41TIxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Ignore this cell if you're not using google colab\n",
        "\n",
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install torch==0.4.0 torchvision\n",
        "import torch\n",
        "print(\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h1o8CJZDSsAO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fct\n",
        "from torch.utils import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from copy import deepcopy\n",
        "from random import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gp0g6lj-WhoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2PR3qkw_ZXK2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Download/Preperation"
      ]
    },
    {
      "metadata": {
        "id": "tvQ7KyV5TeR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P5y2kxzwUtTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train id\n",
        "file_id = '1zF_vQ0PF7TgMS5DyLPSg9tuN5N9BQfKl'\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "\n",
        "lines = downloaded.read().decode(\"utf8\").strip().split(\"\\n\")\n",
        "lines = list(map(lambda line: line.strip().split(\",\"), lines))\n",
        "train_q = [line[0] for line in lines]\n",
        "train_s = [line[1] for line in lines]\n",
        "train_q = np.array(list(map(lambda line: list(map(float, line)), train_q)))\n",
        "train_s = np.array(list(map(lambda line: list(map(float, line)), train_s)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2XKo_2z6SsAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# validation id\n",
        "file_id = '1ToD1YNaqwkEEso_SaD0um7zQ0E1cbNef'\n",
        "\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "\n",
        "lines = downloaded.read().decode(\"utf8\").strip().split(\"\\n\")\n",
        "lines = list(map(lambda line: line.strip().split(\",\"), lines))\n",
        "val_q = [line[0] for line in lines]\n",
        "val_s = [line[1] for line in lines]\n",
        "val_q = np.array(list(map(lambda line: list(map(float, line)), val_q)))\n",
        "val_s = np.array(list(map(lambda line: list(map(float, line)), val_s)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBCs1sqydNX3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test id\n",
        "file_id = '1e_Xksitcc8DS8D3eOx3gINmFvtXmXip8'\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "\n",
        "lines = downloaded.read().decode(\"utf8\").strip().split(\"\\n\")\n",
        "lines = list(map(lambda line: line.strip().split(\",\"), lines))\n",
        "test_q = [line[0] for line in lines]\n",
        "test_s = [line[1] for line in lines]\n",
        "test_q = np.array(list(map(lambda line: list(map(float, line)), test_q))).reshape((-1, 9, 9))\n",
        "test_s = np.array(list(map(lambda line: list(map(float, line)), test_s))).reshape((-1, 9, 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WCAGwvlRbpMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del downloaded, downloader, request, lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e1ZgZDJpSsA5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, xs, ys):\n",
        "        'Initialization'\n",
        "        self.ys = ys\n",
        "        self.xs = xs\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return self.xs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Load data and get label\n",
        "        # relabel the data first randomly\n",
        "        a = list(range(1,10))\n",
        "        b = list(range(1,10))\n",
        "        shuffle(b)\n",
        "        dX = dict(zip(a,b))\n",
        "        dX[0] = 0\n",
        "\n",
        "        X = self.xs[index]\n",
        "        X.apply_(lambda x : dX[x])\n",
        "              \n",
        "        # one-hot-labelling, zero is [1,0,...,0]\n",
        "        one_hot_X = torch.zeros(10,9,9)\n",
        "        one_hot_X.scatter_(0,X.long(),1)\n",
        "\n",
        "        # one-hot-labelling, zero is [0,...,0] and one-hot labels have length of 9\n",
        "        one_hot_X = one_hot_X[1:,:,:]\n",
        "        \n",
        "        y = self.ys[index]\n",
        "        y.apply_(lambda x: dX[x+1]-1)\n",
        "\n",
        "        return one_hot_X, y\n",
        "    \n",
        "    def predict_quiz(self, quiz, i, j):\n",
        "        q = deepcopy(quiz)\n",
        "        if i > 5:\n",
        "            q[0:3,:], q[6:,:] = deepcopy(q[6:,:]), deepcopy(q[0:3,:])\n",
        "        elif i > 2:\n",
        "            q[0:3,:], q[3:6,:] = deepcopy(q[3:6,:]), deepcopy(q[0:3,:])\n",
        "        if i%3 != 0:\n",
        "            q[0,:], q[i%3,:] = deepcopy(q[i%3,:]), deepcopy(q[0,:])\n",
        "\n",
        "        if j > 5:\n",
        "            q[:,0:3], q[:,6:] = deepcopy(q[:,6:]), deepcopy(q[:,0:3])\n",
        "        elif j > 2:\n",
        "            q[:,0:3], q[:,3:6] = deepcopy(q[:,3:6]), deepcopy(q[:,0:3])\n",
        "        if j%3 != 0:\n",
        "            q[:,0], q[:,j%3] = deepcopy(q[:,j%3]), deepcopy(q[:,0])\n",
        "\n",
        "        q = torch.from_numpy(q)\n",
        "        new_quizzes = torch.zeros((1, 10, 9, 9))\n",
        "        poss = q[self.ind[:,0], self.ind[:,1]].type(torch.LongTensor)\n",
        "        new_quizzes[0, poss, self.ind[:,0], self.ind[:,1]] = 1\n",
        "        new_quizzes = new_quizzes.cuda()\n",
        "        out = self(new_quizzes)\n",
        "        conf, pred = torch.max(out, 1)\n",
        "        \n",
        "        return pred, conf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXSwXEgaZl0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tensor_trainq = torch.from_numpy(train_q).type(torch.FloatTensor).reshape(-1,1,9,9)\n",
        "tensor_trains = torch.from_numpy(train_s).type(torch.LongTensor) - 1\n",
        "tensor_valq = torch.from_numpy(val_q).type(torch.FloatTensor).reshape(-1,1,9,9)\n",
        "tensor_vals = torch.from_numpy(val_s).type(torch.LongTensor) - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Az9Fppe9SsBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = data.DataLoader(dataset=Dataset(tensor_trainq,tensor_trains), batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "val_loader = data.DataLoader(dataset=Dataset(tensor_valq,tensor_vals), batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WlwhnEWv01AT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill(quiz, sol, free):\n",
        "    quiz = deepcopy(quiz)\n",
        "    sol = sol.reshape(quiz.shape)\n",
        "    ind = list(zip(*np.where(quiz == 0)))\n",
        "    if ind[0] == (0,0):\n",
        "        ind.pop(0)\n",
        "    else:\n",
        "        RuntimeError(\"Keine freie Stelle oben links\")\n",
        "    shuffle(ind)\n",
        "    while len(ind)-1 > free:\n",
        "        k = ind.pop()\n",
        "        quiz[k] = sol[k]+1\n",
        "    return quiz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nT6v4hFUxauq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill_batch(q_batch, s_batch, free):\n",
        "    q_batch = deepcopy(q_batch)\n",
        "    for k in range(q_batch.shape[0]):\n",
        "        q_batch[k] = fill(q_batch[k], s_batch[k], free)\n",
        "    return q_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P1d-6ch9ZhOW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model"
      ]
    },
    {
      "metadata": {
        "id": "-8iGDWYESsA-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module) :\n",
        "    \n",
        "    def __init__(self) :\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        convs = [None]*CONV_LAYERS\n",
        "        in_filter = 9\n",
        "        for k in range(CONV_LAYERS):\n",
        "            convs[k] = nn.Sequential(\n",
        "                nn.Conv2d(in_filter, FILTERS, padding=PADDING, kernel_size=KERNEL),\n",
        "                nn.ReLU(),\n",
        "            )\n",
        "            in_filter = FILTERS\n",
        "        \n",
        "        in_size = in_filter * 9 * 9\n",
        "\n",
        "        fcs = [None]*FC_LAYERS\n",
        "        for k in range(FC_LAYERS):\n",
        "            if k == FC_LAYERS-1:\n",
        "                fcs[k] = nn.Sequential(\n",
        "                    nn.Linear(in_size, 9),\n",
        "                    nn.LogSoftmax(dim=1),\n",
        "                )\n",
        "            else:\n",
        "                fcs[k] = nn.Sequential(\n",
        "                    nn.Linear(in_size, NEURONS),\n",
        "                    nn.ReLU(),\n",
        "                )\n",
        "                in_size = NEURONS\n",
        "        \n",
        "        self.conv = nn.Sequential(*convs)\n",
        "        self.fc = nn.Sequential(*fcs)\n",
        "        self.drop_out = nn.Dropout(P_DROPOUT)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        #out = self.drop_out(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4UiKK69SsBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = CNN().cuda()\n",
        "name = \"nn_sudoku_{}_{}_{}_{}_{}\".format(CONV_LAYERS, FILTERS, FC_LAYERS, NEURONS, KERNEL)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
        "\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "val_acc = [0]\n",
        "val_pos = [0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHor75jOZnvY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "SPfkrhhBSsBZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.train()\n",
        "tr = train_loader\n",
        "va = val_loader\n",
        "total_step = len(tr)\n",
        "for epoch in range(num_epochs):\n",
        "    acc_ep = []\n",
        "    model.train()\n",
        "    for i, (quizzes, labels) in enumerate(tr):\n",
        "        \n",
        "        quizzes = quizzes.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Run the forward pass\n",
        "        outputs = model(quizzes)\n",
        "        loss = criterion(outputs, labels[:,0])\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Backprop and perform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels[:,0]).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "        acc_ep.append(correct/total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{:2}/{}], Loss: {:.4f}, Accuracy: {:4.1f}%, running Accuracy {:5.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, (i + 1)//100, total_step//100, loss.item(),\n",
        "                          sum(acc_list[-100:]), sum(acc_ep[-500:])/len(acc_ep[-500:])*100))\n",
        "\n",
        "    print(\"\\n\\n\\n\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in va:\n",
        "            \n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "            \n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels[:,0]).sum().item()\n",
        "\n",
        "        print('Validation Accuracy of the model on the {} validation sudokus: {:.2f}%'.format(total, (correct / total) * 100))\n",
        "        val_acc.append(correct / total)\n",
        "        val_pos.append(len(acc_list))\n",
        "        if 100*(val_acc[-1] - val_acc[-2]) < 1: #minor improvement\n",
        "            print(\"Learning rate decrease\")\n",
        "            scheduler.step()\n",
        "\n",
        "    # Save the model and plot\n",
        "    torch.save(model.state_dict(), name)\n",
        "\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "    }\n",
        "    media = MediaFileUpload(name, \n",
        "                            mimetype='application/octet-stream',\n",
        "                            resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata,\n",
        "                                           media_body=media,\n",
        "                                           fields='id').execute()\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "    \n",
        "    print(\"\\n\\n\\n\")\n",
        "print(\"DONE\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H_VaPMLjSsBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in val_loader:\n",
        "        \n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels[:,0]).sum().item()\n",
        "\n",
        "    print('Validation Accuracy of the model on the {} sudokus: {:.2f} %'.format(total, (correct / total) * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZJ0vLjB0Z9tQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plotting"
      ]
    },
    {
      "metadata": {
        "id": "WrgVhse0GFww",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = list(range(len(acc_list)))\n",
        "\n",
        "m_acc, b_acc = np.polyfit(x, acc_list, 1)\n",
        "regr_acc = [m_acc*i+b_acc for i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZQ3nxWxGnmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = list(range(len(loss_list)))\n",
        "\n",
        "m_loss, b_loss = np.polyfit(x, loss_list, 1)\n",
        "regr_loss = [m_loss*i+b_loss for i in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGRqCYgRPAN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "fig.set_dpi(100)\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "plt.grid(alpha=0)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "ax1.set_xlabel(\"#steps\")\n",
        "ax1.set_ylabel(\"accuracy\")\n",
        "ax2.set_ylabel(\"loss\")\n",
        "ax1.set_ylim([0,1])\n",
        "ax2.set_ylim([0,max(loss_list)+.3])\n",
        "ax1.set_xlim([0,max(len(loss_list), len(acc_list))])\n",
        "\n",
        "ax2.plot(loss_list, \"g\",label=\"loss\")\n",
        "ax2.plot(regr_loss, \"y\",label=\"loss regression line\")\n",
        "\n",
        "ax1.plot(acc_list, \"b\",label=\"accuracy\")\n",
        "ax1.plot(regr_acc, \"c\",label=\"accuracy regression line\")\n",
        "ax1.plot(val_pos, val_acc, \"ro\", label=\"validation accuracy\")\n",
        "\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0,color='black')\n",
        "plt.axvline(max(len(loss_list), len(acc_list)),color='black')\n",
        "\n",
        "lgd1 = ax1.legend(bbox_to_anchor=(1.1, 1), loc=2, borderaxespad=0.)\n",
        "lgd2 = ax2.legend(bbox_to_anchor=(1.1, .8), loc=2, borderaxespad=0.)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.savefig(\"plot_\"+name+\".png\" ,bbox_extra_artists=(lgd1,lgd2), bbox_inches='tight')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pEnzJoU4asqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save Data"
      ]
    },
    {
      "metadata": {
        "id": "91baMSd7KlH7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_metadata = {\n",
        "      'name': \"plot_\"+name+\".png\",\n",
        "      'mimeType': 'image/png'\n",
        "    }\n",
        "media = MediaFileUpload(\"plot_\"+name+\".png\", \n",
        "                        mimetype='image/png',\n",
        "                        resumable=True)\n",
        "\n",
        "created = drive_service.files().create(body=file_metadata,\n",
        "                                       media_body=media,\n",
        "                                       fields='id').execute()\n",
        "print('File ID: {}'.format(created.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYSC56ajJCvU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ]
    },
    {
      "metadata": {
        "id": "DeVEwjvkQLRX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "count = 0\n",
        "for quiz,solved in zip(test2_q, test2_s):\n",
        "    \n",
        "    if count == 100 :\n",
        "        break\n",
        "    \n",
        "    quiz = deepcopy(quiz)\n",
        "    inds = list(zip(*np.where(quiz == 0)))\n",
        "    \n",
        "    while len(inds) > 0:\n",
        "        i, j = inds.pop()\n",
        "        pred, conf = model.predict_quiz(quiz, i, j)\n",
        "        if pred+1 == solved[i, j]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    \n",
        "    count += 1\n",
        "    if count % 1000 == 0:\n",
        "        print(count, end=\" \")\n",
        "print()\n",
        "print('Test Accuracy of the model on the {} cells: {:.2f}%'.format(total, (correct / total) * 100))      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pLUgumB_XTKX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "amn_hints = [[0,0] for _ in range(81)]\n",
        "compl_solved = 0\n",
        "count = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for quiz,solved in zip(test2_q, test2_s):\n",
        "\n",
        "        if count == 1000 :\n",
        "            break\n",
        "        \n",
        "        \n",
        "        quiz = deepcopy(quiz)\n",
        "        inds = list(zip(*np.where(quiz == 0)))\n",
        "        empty = len(inds)\n",
        "        accs.append(0)\n",
        "        correct = True\n",
        "\n",
        "        while len(inds) > 0:\n",
        "            maxis = (-np.inf, 0, 0, 0) # confidence, i, j, pred\n",
        "            for i, j in inds:\n",
        "                pred, conf = model.predict_quiz(quiz, i, j)\n",
        "                if conf > maxis[0]:\n",
        "                    maxis = (conf, i, j, pred)\n",
        "            conf, i, j, pred = maxis\n",
        "            if pred+1 == solved[i, j]:\n",
        "                accs[-1] += 1\n",
        "                amn_hints[81-len(inds)][0] += 1\n",
        "            else:\n",
        "                correct = False\n",
        "            amn_hints[81-len(inds)][1] += 1\n",
        "            inds.pop(inds.index((i, j)))\n",
        "            quiz[i][j] = solved[i][j]\n",
        "        count += 1\n",
        "        accs[-1] /= empty\n",
        "        compl_solved += correct\n",
        "        if count % 200 == 0:\n",
        "            print(count, \"\\n\", end=\"\")\n",
        "        elif count % 10 == 0 :\n",
        "            print(count, end=\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U6hVrsUfGx5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc_hints = list(enumerate(amn_hints))\n",
        "for i in range(81):\n",
        "    if acc_hints[i][1][1] != 0:\n",
        "        break\n",
        "acc_hints = acc_hints[i:]\n",
        "acc_hints = np.array([[i, amn[0]/amn[1]] for i, amn in acc_hints])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-PXy7RhVH1jZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Completed correct:\", compl_solved, compl_solved / count\n",
        "print(\"Average accuracy:\", np.mean(accs), np.std(accs))\n",
        "plt.plot(acc_hints[:,0], acc_hints[:,1]*100, color=\"red\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVng8YzlDbdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "quiz = np.array([[8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "               [0, 0, 3, 6, 0, 0, 0, 0, 0],\n",
        "               [0, 7, 0, 0, 9, 0, 2, 0, 0],\n",
        "               [0, 5, 0, 0, 0, 7, 0, 0, 0],\n",
        "               [0, 0, 0, 0, 4, 5, 7, 0, 0],\n",
        "               [0, 0, 0, 1, 0, 0, 0, 3, 0],\n",
        "               [0, 0, 1, 0, 0, 0, 0, 6, 8],\n",
        "               [0, 0, 8, 5, 0, 0, 0, 1, 0],\n",
        "               [0, 9, 0, 0, 0, 0, 4, 0, 0]])\n",
        "solved = np.array([[8, 1, 2, 7, 5, 3, 6, 4, 9],\n",
        "              [9, 4, 3, 6, 8, 2, 1, 7, 5],\n",
        "              [6, 7, 5, 4, 9, 1, 2, 8, 3],\n",
        "              [1, 5, 4, 2, 3, 7, 8, 9, 6],\n",
        "              [3, 6, 9, 8, 4, 5, 7, 2, 1],\n",
        "              [2, 8, 7, 1, 6, 9, 5, 3, 4],\n",
        "              [5, 2, 1, 9, 7, 4, 3, 6, 8],\n",
        "              [4, 3, 8, 5, 2, 6, 9, 1, 7],\n",
        "              [7, 9, 6, 3, 1, 8, 4, 5, 2]])\n",
        "inds = list(zip(*np.where(quiz == 0)))\n",
        "t = len(inds)\n",
        "c = 0\n",
        "\n",
        "while len(inds) > 0:\n",
        "    maxis = (-np.inf, 0, 0, 0) # confidence, i, j, pred\n",
        "    for i, j in inds:\n",
        "        pred, conf = model.predict_quiz(quiz, i, j)\n",
        "        if conf > maxis[0]:\n",
        "            maxis = (conf, i, j, pred)\n",
        "    conf, i, j, pred = maxis\n",
        "    if int(pred+1) == solved[i, j]:\n",
        "        c += 1\n",
        "        print(i, j, int(pred)+1, solved[i][j])\n",
        "    else:\n",
        "        print(\"\\t\", i, j, int(pred)+1, solved[i][j])\n",
        "    inds.pop(inds.index((i, j)))\n",
        "    quiz[i][j] = solved[i][j]\n",
        "print(c/t, c, t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gk0QiOEVanPX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ]
    },
    {
      "metadata": {
        "id": "yICjxjtR8ns4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_id = '1VZ0p4PoJYq8Adj3Nb9VY74oy0_r7Z_hG'\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "with open(\"state.ckpt\", \"wb\") as file:\n",
        "    file.write(downloaded.read())\n",
        "del downloaded, downloader, request"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cbssSf-8vYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"state.ckpt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}